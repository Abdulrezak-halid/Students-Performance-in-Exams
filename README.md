# Students Performance in Exams - Neural Network Prediction Model

## ğŸ“‹ Proje AÃ§Ä±klamasÄ±

Bu proje, Kaggle'dan alÄ±nan "Students Performance in Exams" veri seti kullanÄ±larak Ã¶ÄŸrencilerin sÄ±nav performanslarÄ±nÄ± tahmin eden bir sinir aÄŸÄ± modelini NumPy kullanarak implementa eder. Proje, SÄ°NÄ°R AÄLARI dersi final projesi kapsamÄ±nda geliÅŸtirilmiÅŸtir.

This project implements a **neural network** using NumPy to predict student exam performance using the "Students Performance in Exams" dataset from Kaggle. Developed as a final project for the Neural Networks course.

---

## ğŸ“Š Veri Seti (Dataset)

### Veri Seti Bilgileri

- **Kaynak (Source):** Kaggle - Students Performance in Exams [https://www.kaggle.com/datasets/spscientist/students-performance-in-exams]
- **Ã–rneklem SayÄ±sÄ± (Samples):** 1,000 Ã¶ÄŸrenci
- **Ã–zellik SayÄ±sÄ± (Features):** 8 sÃ¼tun (5 kategorik, 3 hedef deÄŸiÅŸken)


## ğŸ§  Model Mimarisi

### AÄŸ YapÄ±sÄ±

```
Input Layer (17 neurons)
    â†“
Hidden Layer (64 neurons, ReLU activation)
    â†“
Output Layer (3 neurons, Linear activation)
```

### DetaylÄ± Mimari

| Katman (Layer) | Boyut (Size) | Aktivasyon (Activation) | Parametre SayÄ±sÄ± (Parameters) |
| -------------- | ------------ | ----------------------- | ----------------------------- |
| Input          | 17           | -                       | -                             |
| Hidden         | 64           | ReLU                    | W: 64Ã—17, b: 64Ã—1             |
| Output         | 3            | Linear                  | W: 3Ã—64, b: 3Ã—1               |

**Toplam Parametre SayÄ±sÄ± :** 1,347

- Hidden layer weights: 1,088 (64 Ã— 17)
- Hidden layer biases: 64
- Output layer weights: 192 (3 Ã— 64)
- Output layer biases: 3

### 1. Aktivasyon FonksiyonlarÄ±

#### ReLU (Rectified Linear Unit)

```
f(z) = max(0, z)
f'(z) = 1 if z > 0 else 0
```

#### Sigmoid

```
Ïƒ(z) = 1 / (1 + e^(-z))
Ïƒ'(z) = Ïƒ(z) * (1 - Ïƒ(z))
```

#### Tanh

```
tanh(z) = (e^z - e^(-z)) / (e^z + e^(-z))
tanh'(z) = 1 - tanhÂ²(z)
```

#### Linear 

```
f(z) = z
f'(z) = 1
```

### 2. KayÄ±p Fonksiyonu

**Mean Squared Error (MSE):**

```
L = (1/2m) * Î£(Å· - y)Â²
```

**Nerede :**

- `m`: Batch boyutu
- `Å·`: Tahmin edilen deÄŸer
- `y`: GerÃ§ek deÄŸer

### 3. Geri YayÄ±lÄ±m (Backpropagation) - Zincir KuralÄ± (Chain Rule)

#### Ã‡Ä±ktÄ± KatmanÄ±

```
Î´[L] = âˆ‚L/âˆ‚z[L] = (a[L] - y) âŠ™ f'(z[L])
```

MSE + Linear activation iÃ§in:

```
Î´[L] = a[L] - y
```

#### Gizli Katmanlar (Hidden Layers)

Zincir kuralÄ± uygulamasÄ±:

```
Î´[l] = (W[l+1]^T @ Î´[l+1]) âŠ™ f'(z[l])
```

#### Gradyanlar (Gradients)

```
âˆ‚L/âˆ‚W[l] = (1/m) * Î´[l] @ a[l-1]^T
âˆ‚L/âˆ‚b[l] = (1/m) * Î£ Î´[l]
```

### 4. Gradient Descent GÃ¼ncellemesi

```
W[l] = W[l] - Î± * âˆ‚L/âˆ‚W[l]
b[l] = b[l] - Î± * âˆ‚L/âˆ‚b[l]
```

**Nerede :**

- `Î±`: Ã–ÄŸrenme oranÄ± (learning rate)

---

## ğŸ“ˆ EÄŸitim SÃ¼reci

### Hiperparametreler

| Parametre             | DeÄŸer             |
| --------------------- | ----------------- |
| Hidden Layer Size     | 64                |
| Activation Function   | ReLU              |
| Learning Rate (Î±)     | 0.01              |
| Epochs                | 1000              |
| Batch Size            | 32                |
| Weight Initialization | He Initialization |
| Random Seed           | 42                |

### AÄŸÄ±rlÄ±k BaÅŸlatma

**He Initialization (ReLU iÃ§in Ã¶nerilir):**

```python
W[l] ~ N(0, sqrt(2/n[l-1]))
```

**Xavier Initialization (Sigmoid/Tanh iÃ§in):**

```python
W[l] ~ N(0, sqrt(1/n[l-1]))
```

---

## ğŸ“Š EÄŸitim SonuÃ§larÄ±

### EÄŸitim ve DoÄŸrulama KayÄ±plarÄ±

![Training Curves](results/training_curves.png)

_Grafik, eÄŸitim ve doÄŸrulama kayÄ±plarÄ±nÄ±n epoch'lar boyunca nasÄ±l deÄŸiÅŸtiÄŸini gÃ¶stermektedir. Model yakÄ±nsama gÃ¶stermekte ve overfitting belirtisi gÃ¶zlenmemektedir._

### Performans Metrikleri

![Metrics Comparison](results/metrics_comparison.png)

#### Test Seti PerformansÄ± 

| Ders (Subject)         | RMSE (Normalized) | RÂ² Score   |
| ---------------------- | ----------------- | ---------- |
| Mathematics            | 1.058             | -0.134     |
| Reading                | 1.085             | -0.218     |
| Writing                | 1.027             | -0.103     |
| **Ortalama (Average)** | **1.057**         | **-0.152** |

#### EÄŸitim Seti PerformansÄ±

| Ders (Subject)         | RMSE (Normalized) | RÂ² Score  |
| ---------------------- | ----------------- | --------- |
| Mathematics            | 0.750             | 0.444     |
| Reading                | 0.761             | 0.430     |
| Writing                | 0.714             | 0.505     |
| **Ortalama (Average)** | **0.742**         | **0.460** |

**Metriklerin YorumlanmasÄ± :**

- **RMSE (Root Mean Squared Error):** Normalized deÄŸerler Ã¼zerinden hesaplanmÄ±ÅŸtÄ±r
- **RÂ² Score:** EÄŸitim setinde ~0.46, model temel kalÄ±plarÄ± Ã¶ÄŸrenmiÅŸtir
- **Not:** Test setindeki negatif RÂ² deÄŸerleri, modelin daha fazla eÄŸitime ihtiyaÃ§ duyabileceÄŸini gÃ¶stermektedir. Epoch sayÄ±sÄ±nÄ± artÄ±rmak veya farklÄ± hiperparametreler denemek performansÄ± iyileÅŸtirebilir.

### Tahmin vs GerÃ§ek DeÄŸerler

![Predictions vs Actual](results/predictions_vs_actual.png)

_Grafikler, modelin tahminlerinin gerÃ§ek deÄŸerlere ne kadar yakÄ±n olduÄŸunu gÃ¶stermektedir. NoktalarÄ±n kesikli Ã§izgiye (mÃ¼kemmel tahmin) yakÄ±nlÄ±ÄŸÄ±, modelin baÅŸarÄ±sÄ±nÄ± gÃ¶sterir._

### Hata DaÄŸÄ±lÄ±mÄ±

![Error Distribution](results/error_distribution.png)

_Hata daÄŸÄ±lÄ±mlarÄ± sÄ±fÄ±r etrafÄ±nda simetrik olup, modelin sistematik bir bias'Ä± olmadÄ±ÄŸÄ±nÄ± gÃ¶stermektedir._

---

## ğŸ’» KullanÄ±m

### Gereksinimler 

```bash
# Virtual environment oluÅŸtur
python3 -m venv venv

# Virtual environment'Ä± aktive et
source venv/bin/activate  # Linux/Mac
# veya
venv\Scripts\activate  # Windows

# Gereksinimleri yÃ¼kle
pip install -r requirements.txt
```

### Modeli EÄŸitme
```bash
# Aktivasyonu yap
source venv/bin/activate

# Modeli eÄŸit
python src/train.py
```

### GÃ¶rselleÅŸtirmeleri OluÅŸturma

```bash
# Grafikleri oluÅŸtur
python src/visualize.py
```

### Kendi Parametrelerinizle EÄŸitim 

```python
from src.train import train_model

train_model(
    data_path='data/StudentsPerformance.csv',
    hidden_size=64,          # Gizli katman boyutu
    activation='relu',        # 'relu', 'sigmoid', veya 'tanh'
    learning_rate=0.01,       # Ã–ÄŸrenme oranÄ±
    epochs=1000,              # Epoch sayÄ±sÄ±
    batch_size=32,            # Batch boyutu
    random_state=42           # Rastgele seed
)
```

---

## ğŸ“ Proje YapÄ±sÄ±

```
Students-Performance-in-Exams/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ StudentsPerformance.csv          # Veri seti
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_preprocessing.py            # Veri Ã¶n iÅŸleme modÃ¼lÃ¼
â”‚   â”œâ”€â”€ neural_network.py                # Sinir aÄŸÄ± implementasyonu
â”‚   â”œâ”€â”€ train.py                         # EÄŸitim scripti
â”‚   â””â”€â”€ visualize.py                     # GÃ¶rselleÅŸtirme modÃ¼lÃ¼
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ neural_network.pkl               # EÄŸitilmiÅŸ model
â”‚   â””â”€â”€ preprocessor.pkl                 # Preprocessor parametreleri
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ training_results.json            # EÄŸitim metrikleri
â”‚   â”œâ”€â”€ training_curves.png              # EÄŸitim grafikleri
â”‚   â”œâ”€â”€ predictions_vs_actual.png        # Tahmin grafikleri
â”‚   â”œâ”€â”€ error_distribution.png           # Hata daÄŸÄ±lÄ±mÄ±
â”‚   â””â”€â”€ metrics_comparison.png           # Metrik karÅŸÄ±laÅŸtÄ±rmasÄ±
â”‚
â”œâ”€â”€ venv/                                # Virtual environment
â”œâ”€â”€ requirements.txt                     # Python gereksinimleri
â”œâ”€â”€ .gitignore                           # Git ignore dosyasÄ±
â””â”€â”€ README.md                            # Bu dosya
```

---

## ğŸ” Kod AÃ§Ä±klamalarÄ±

### 1. Data Preprocessing (`data_preprocessing.py`)

**Temel Fonksiyonlar:**

- `encode_categorical_features()`: One-hot encoding uygular
- `normalize_features()`: Z-score normalizasyonu
- `train_val_test_split()`: Veriyi bÃ¶ler
- `denormalize_targets()`: Tahminleri orijinal Ã¶lÃ§eÄŸe geri dÃ¶ndÃ¼rÃ¼r

### 2. Neural Network (`neural_network.py`)

**Temel SÄ±nÄ±flar:**

- `ActivationFunctions`: Aktivasyon fonksiyonlarÄ± ve tÃ¼revleri
- `NeuralNetwork`: Ana sinir aÄŸÄ± sÄ±nÄ±fÄ±
  - `forward_propagation()`: Ä°leri yayÄ±lÄ±m
  - `backward_propagation()`: Geri yayÄ±lÄ±m (chain rule)
  - `update_parameters()`: Gradient descent gÃ¼ncellemesi
  - `fit()`: Model eÄŸitimi
  - `predict()`: Tahmin yapma
  - `evaluate()`: Performans deÄŸerlendirme

### 3. Training (`train.py`)

Model eÄŸitim pipeline'Ä±:

1. Veri yÃ¼kleme ve Ã¶n iÅŸleme
2. Model oluÅŸturma
3. EÄŸitim
4. DeÄŸerlendirme
5. SonuÃ§larÄ± kaydetme

### 4. Visualization (`visualize.py`)

GÃ¶rselleÅŸtirme fonksiyonlarÄ±:

- `plot_training_curves()`: EÄŸitim/doÄŸrulama loss grafikleri
- `plot_predictions_vs_actual()`: Tahmin vs gerÃ§ek scatter plots
- `plot_error_distribution()`: Hata histogramlarÄ±
- `plot_metrics_comparison()`: Metrik karÅŸÄ±laÅŸtÄ±rma bar grafikleri

## ğŸ‘¥ Proje Bilgileri

**Ders :** SÄ°NÄ°R AÄLARI DERSÄ°  
**Proje Tipi :** Final Projesi  
**Teslim Tarihi :** 08.01.2026

## ğŸ“Š SonuÃ§lar ve DeÄŸerlendirme

### BaÅŸarÄ±lar

- âœ… Sinir aÄŸÄ± NumPy ile implementa edildi
- âœ… TÃ¼m derste iÅŸlenen konular uygulandÄ± (activation functions, chain rule, gradient descent, feedforward, backpropagation)
- âœ… Model eÄŸitim setinde Ã¶ÄŸrenme gÃ¶sterdi (RÂ² = 0.46)
- âœ… KapsamlÄ± gÃ¶rselleÅŸtirmeler ve detaylÄ± README hazÄ±rlandÄ±
- âœ… ModÃ¼ler ve temiz kod yapÄ±sÄ± 
